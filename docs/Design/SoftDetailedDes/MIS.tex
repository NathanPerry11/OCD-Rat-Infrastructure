\documentclass[12pt, titlepage]{article}

\usepackage{amsmath, mathtools}

\usepackage[round]{natbib}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xr}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[section]{placeins}
\usepackage{caption}
\usepackage{fullpage}

\hypersetup{
bookmarks=true,     % show bookmarks bar?
colorlinks=true,       % false: boxed links; true: colored links
linkcolor=red,          % color of internal links (change box color with linkbordercolor)
citecolor=blue,      % color of links to bibliography
filecolor=magenta,  % color of file links
urlcolor=cyan          % color of external links
}

\usepackage{array}

\externaldocument{../../SRS/SRS}

\input{../../Comments}
\input{../../Common}

\begin{document}

\title{Module Interface Specification for \progname{}}

\author{\authname}

\date{\today}

\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Date 1 & 1.0 & Notes\\
Date 2 & 1.1 & Notes\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

See SRS Documentation at \wss{give url}

\wss{Also add any additional symbols, abbreviations or acronyms}

\newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Introduction}

The following document details the Module Interface Specifications for
\wss{Fill in your project name and description}

Complementary documents include the System Requirement Specifications
and Module Guide.  The full documentation and implementation can be
found at \url{...}.  \wss{provide the url for your repo}

\section{Notation}

This document adopts a formal notation and structural convention to describe the architecture and module interface specifications (MIS) for the Behavioral Data Analysis Platform for Animal Models of OCD. 

The structure of each MIS follows the framework of \citet{HoffmanAndStrooper1995}, extended to incorporate template modules as described by \citet{GhezziEtAl2003}. The mathematical and logical notation is consistent with Chapter 3 of \citet{HoffmanAndStrooper1995}, with domain-specific adaptations for data processing and behavioral event analysis.

\subsection*{Mathematical and Logical Conventions}

\begin{itemize}
    \item The symbol \texttt{:=} denotes an assignment or multiple assignment statement.  
    For example, \texttt{session.avg\_latency := sum(latency) / count(latency)}.

    \item Conditional expressions follow the form:
    \[
        (c_1 \Rightarrow r_1 \;|\; c_2 \Rightarrow r_2 \;|\; \dots \;|\; c_n \Rightarrow r_n)
    \]
    For instance:
    \[
        (\text{event.type = "drug 1"} \Rightarrow \text{increment(count)} \;|\; \text{event.type = "drug 2"} \Rightarrow \text{record(duration)})
    \]
    where the rule corresponding to the first true condition is applied.

    \item Logical connectives are used as follows:
    \begin{itemize}
        \item \(\land\) — logical AND  
        \item \(\lor\) — logical OR  
        \item ` — logical NOT  
        \item \(\Rightarrow\) — implication
    \end{itemize}

    \item Set notation follows standard mathematical conventions:  
    \(\{x \mid P(x)\}\) represents the set of all \(x\) satisfying predicate \(P(x)\).  
    Example:  
    \(\{ e \in Events \mid e.duration > 10s \}\) denotes the set of long-duration events.

    \item Ranges are denoted as \([a..b]\), representing all integer time indices \(t\) such that \(a \leq t \leq b\).

    \item Function definitions are expressed as mappings:  
    \[
        f : Input \rightarrow Output
    \]
    Example:  
    \[
        \texttt{computeMetrics} : SessionData \rightarrow BehavioralSummary
    \]
\end{itemize}

\subsection*{Data and Type Notation}

\begin{itemize}
    \item \(Session\) — a structured dataset representing a single experimental trial.  
    \item \(Event\) — a tuple of attributes describing a behavioral observation, e.g. \((type, timestamp, duration)\).
    \item \(Metric\) — a computed quantitative value derived from one or more events.
    \item \(AnimalID\) — a unique identifier for a subject.
    \item \(TrialSet := \{ s_1, s_2, ..., s_n \}\) — the set of all sessions recorded for a given animal.
\end{itemize}

\subsection*{Units and Measurement Conventions}
\begin{itemize}
    \item Time values are expressed in seconds (s).  
    \item Counts and frequencies are represented as integers.  
    \item Statistical metrics (e.g., mean, standard deviation, z-score) are expressed as real numbers (\(\mathbb{R}\)).
\end{itemize}

These conventions are used consistently throughout the system specification to ensure mathematical clarity and facilitate unambiguous interpretation of the behavioral data models, algorithms, and transformations.


\section{Module Decomposition}

The following table is taken directly from the Module Guide document for this project.

\begin{table}[h!]
  \centering
  \begin{tabular}{p{0.3\textwidth} p{0.6\textwidth}}
  \toprule
  \textbf{Level 1} & \textbf{Level 2}\\
  \midrule
  
  {Hardware-Hiding Module} & ~ \\
  \midrule
  
  \multirow{3}{0.3\textwidth}{Behaviour-Hiding Module} & Front-End Interface Module\\
  & API Layer Module\\
  & Data Schema and Storage Module\\
  & Data Visualization Module\\
  \midrule
  
  \multirow{4}{0.3\textwidth}{Software Decision Module} & NLP Query Processor \\
  & Data Processing Pipeline Module\\
  & Authentication and Access Control Module\\
  & Fault and Error Management Module\\
  & Security and Dependency Management Module\\
  \bottomrule
  
  \end{tabular}
  \caption{Module Hierarchy}
  \label{TblMH}
  \end{table}

\newpage
~\newpage

\section{MIS of \wss{Module Name}} \label{Module} \wss{Use labels for
  cross-referencing}

\wss{You can reference SRS labels, such as R\ref{R_Inputs}.}

\wss{It is also possible to use \LaTeX for hypperlinks to external documents.}

\subsection{Module}

\wss{Short name for the module}

\subsection{Uses}


\subsection{Syntax}

\subsubsection{Exported Constants}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{2cm} p{4cm} p{4cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\wss{accessProg} & - & - & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

\wss{Not all modules will have state variables.  State variables give the module
  a memory.}

\subsubsection{Environment Variables}

\wss{This section is not necessary for all modules.  Its purpose is to capture
  when the module has external interaction with the environment, such as for a
  device driver, screen interface, keyboard, file, etc.}

\subsubsection{Assumptions}

\wss{Try to minimize assumptions and anticipate programmer errors via
  exceptions, but for practical purposes assumptions are sometimes appropriate.}

\subsubsection{Access Routine Semantics}

\noindent \wss{accessProg}():
\begin{itemize}
\item transition: \wss{if appropriate} 
\item output: \wss{if appropriate} 
\item exception: \wss{if appropriate} 
\end{itemize}

\wss{A module without environment variables or state variables is unlikely to
  have a state transition.  In this case a state transition can only occur if
  the module is changing the state of another module.}

\wss{Modules rarely have both a transition and an output.  In most cases you
  will have one or the other.}

\subsubsection{Local Functions}

\wss{As appropriate} \wss{These functions are for the purpose of specification.
  They are not necessarily something that is going to be implemented
  explicitly.  Even if they are implemented, they are not exported; they only
  have local scope.}

\newpage

\bibliographystyle {plainnat}
\bibliography {../../../refs/References}

\newpage

\section{Appendix} \label{Appendix}

\wss{Extra information if required}

\newpage{}

\section*{Appendix --- Reflection}

\wss{Not required for CAS 741 projects}

The information in this section will be used to evaluate the team members on the
graduate attribute of Problem Analysis and Design.

\input{../../Reflection.tex}

\begin{enumerate}
  \item What went well while writing this deliverable? 

  The team was much more focused this deliverable than we had been for the previous deliverable (VnV Plan). Now that
  midterms are over, we had more time to really spend a lot of time trying to do this deliverable well. The previous deliverable
  was less of a priority due to the midterms dwarfing it in terms of grade weight. We think this resulted in a more well done,
  coherent and complete deliverable that puts us in a good spot as we begin the implementation of our system. Additionally, the teamwork
  aspect of this deliverable was also quite good this deliverable. This likely also ties back into having more time in general but group
  members were more willing to take on more parts and help others that needed it. Two members even focused largely on the PoC rather than
  writing the design document because the other three members had the capacity to shoulder a larger documentation load.

  \item What pain points did you experience during this deliverable, and how
    did you resolve them?

    There were not too many major pain points experienced during this deliverable, it generally went quite well. The first pain point of note
    would be ensuring consistency across all parts and between documents. Although we work as a team, we mainly complete the section individually
    and thus we need to ensure that two members don't write things in different sections that are not aligned with each other. This deliverable's sections
    were the most interconnected yet and thus it will require a pretty thorough document review to ensure everything is consistent. The second pain point
    for this deliverable was the MIS design of each module. This was the final section to be completed as we were not quite sure how to split it up or exactly
    what was required. As it turns out this is not just one section but rather a section for each module (so essentially 10 additional sections of the document)
    which was quite a large workload to complete, especially since it was left right until the end. This was simply resolved by splitting up the modules based
    on who had the capacity to take them on and to commit the needed time to completing it. As mentioned earlier, members generally had time to do this so it wasn't
    a terribly painful process.

  \item Which of your design decisions stemmed from speaking to your client(s)
  or a proxy (e.g. your peers, stakeholders, potential users)? For those that
  were not, why, and where did they come from?

    First and foremost, essentially all of module 5 was developed by speaking with our client, Dr. Henry Szechtman. He
    is the definitive expert on these datasets and thus he is most equipped to develop a schema for our system. Luckily, he
    has enough technical knowledge to develop this for us to look over and decide if it is workable, which we believe it is.
    Additionally, the data-processing module, the visualization module and the front-end module were all largely influenced by our discussions
    with Dr.Szechtman, specficially through him describing to us what specific functions he wants the system to have (e.g. data processing abilities,
    front-end design, available visualizations). Outside of these design aspects, most of the rest of the design was created outside of
    much influence from our client. This includes things like the natural language processing module, the fault and error management module, the API
    layer module etc... The reason that these decisions were not made based on client interactions is because they are more purely part
    of what could be called the 'intermediate technical design' rather than user specifications. For example, the natural language processing
    module requires it to be designed such that natural language can be accurately converted into a SQL query. Alternatively, the error management
    module simply regulates UI, API and query inputs to prevent any undesired behaviour. Both of these design outlines do not require
    much input from the client/users as they are basically purely technical implementation (there are not really many different ways to specify natural
    language into a SQL query). As such, they are left to the technical experts which are the members of our group.

  \item While creating the design doc, what parts of your other documents (e.g.
  requirements, hazard analysis, etc), it any, needed to be changed, and why?

  \begin{enumerate}
    \item{Our functional requirement related to serving pre-defined datasets will need to be revised. After further discussion with our client,
          we elicited this requirement in more detail and he is looking more so for a 'web store' outline in the sense that you can sort through
          the available records based on various available categories rather than displaying specific data sets as 'products' which is how we initially
          understood it.}
    \item{Our database schema containing all of the data related to the session trials will now be implemented specifically using a PostGres SQL server.
          This will need to be specified in our SRS.}
    \item{We are not technically using the FRDR API directly because it only serves the metadata for the datasets. Accessing the data objects themselves
          are done via an HTTP request to a specified URL that the FRDR organization provides to us. This is not technically using the API and is rather
          just making HTTP requests to publicly available URLs that exist within the FRDR domain. This requirement should be updated accordingly.}
    \item{Likewise, our hazard related to the API layer should be slightly augmented since we are going to be dealing with HTTP requests. This hazard
    should now focus on hazards related specifically to HTTP such as what could happen due to various error codes and othe related issues that could
    come up.}
    \item{Initially, the idea for our database was that all the data is publicly available to all users at all times. We are beginning to develop
    a new requirement which would both be an addition (as it's a new requirement) and a revision to this publicly available clause. The idea
    is that users can essentially create a materialized view for their experiments and save them on the database so that other users can view them.
    However, in the case that they are not allowed to make the details of their experiment public, we would like to restrict access to this view for a set
    time period (maybe one year after the experiment is created).}
  \end{enumerate}
  \item What are the limitations of your solution?  Put another way, given
  unlimited resources, what could you do to make the project better? (LO\_ProbSolutions)

    A major limitation of our solution is the resources available for running our server and backend. The total amount of disk space taken up by 
    all of the data objects that are relevant to our project is about 11 terabytes. This amount of space is not feasible for our server, not to mention
    the amount of computational resources required to do data processing on all of that data. If this were not an issue, hosting all of the data objects
    on our server without the need to interact with the FRDR API to access the files would greatly streamline the workflow, likely improve performance
    of our system and also give us more control over our implementation without the need to conform and work around the specifications of FRDR.

    A secondary limitation of our system is our access to LLMs and other machine learning models. Natural language processing and behavioural cateogorization are important parts of our
    system. However, we realistically do not have the resources or expertise to develop our own model for these specific purposes and will have to rely
    on Off-The-Shelf software or external systems for these purposes. We can make the best of this by using system prompts to guide the model in the exact direction
    we need it to go, add error checking for coherent results or even train the model with our available data if needed. None of these would be quite as 
    effective as developing a model specifically for the intended purpose of natural language input into query output or behavioral categorizations of rats.

    Finally, maybe the biggest limitation for us is our lack of time. The lack of time is twofold. First, we only have about 6 more months to build the project 
    and secondly, the entire team will likely have 5 other courses happening the entire time we are working on it. It is very common for capstone teams to not
    build anything close to a finalized project, sometimes it doesn't even work at all really. We envision that we will land somewhere in the middle but the time limit
    imposed on us almost guarantees that we will not be able to implement the plethora of integrations desired for this system. From natural language input to extensive
    behavioural categorizations to countless possible visualizations of the datasets and statistical information we could potentially provide that would be useful for
    future researchers, the chances we are able to implement a complete toolbox of these functionalities is slim to none.

  \item Give a brief overview of other design solutions you considered.  What
  are the benefits and tradeoffs of those other designs compared with the chosen
  design?  From all the potential options, why did you select the documented design?
  (LO\_Explores)

  We actually did not consider too many different design options for two reasons. The first is that a previous iteration of this project already
  exists so our supervisor has a general idea of what he wants it to look like and thus we are expected to mostly conform to the general outline
  that was devised by him and last year's team. So, they most broad high level conceptual design was already mostly predetermined when the project started.
  Secondly, when talking about the system architecture, since this will essentially be a full-stack web application with many integrations, it is kind
  of automatically assumed that an MVC architecture or something that approximates that will be used as that is the bog standard for this sort of project.
  Of course, there are many more aspects to the design (especially at slightly higher granularity) that had a couple options for us to decide on. Below are a
  few of possible design alternatives and our reasoning for avoiding them.

  \begin{enumerate}
    \item{Exclusively using the FRDR API to query the relevant data rather than producing a seperate database schema which then points us to the relevant
    endpoints in the FRDR domain. This would allow us to avoid needing to create a database and load all ~20,000 session details into the schema. This
    might have been useful if there were an order of magnitude or two more sessions and storing them ourselves would become an issue. In the end, making
    a schema streamlines the query process and gives us more control over data processing. Furthermore, after investigating the FRDR API, accessing this
    data would have actually been a lot more difficult than we initially had expected.}
    \item{Buying our own personal LLM model (likely would be
    a mostly blank model to be trained) that could run on our application server rather than using an LLM API (such as the OpenAI API). This
    would actually likely improve the accuracy of our prompts if we could train it on the relevant trial data. However, the main concerns with this
    would be the potential lack of data to train it enough to be beneficial (we only have about 20,000 trials, the model may need millions of
    data points) and that it may be quite expensive to purchase a full model for our personal use. In the end, we figured that using an LLM API
    with a sufficient system prompt to guide it's response would be the most cost-effective route that we are confident will provide good enough
    results for our purposes.}
    \item{This is more of a subtle design alternative but one of our modules handles error detection and fault tolerance. This will provide the means
    to track, log and provide details on the various errors that can be raised by the various different modules (such as bad HTTP requests, invalid
    NLP responses etc...). We heavily considered removing this module and leaving this up to each individual module as we thought it would simplify
    the implementation (one less module after all). However, in the end we decided that having a unified error management module would it make it
    easier to track and manage errors across modules as well as ensure they are reported consistently.}
    \item{Using a different front-end development kit other than React. We considered building the front-end from the ground up using HTML/CSS/JavaScript
    as we felt it would give us more control over the interface and would be more purely our work rather than relying on components created by other people.
    However, in the end we decided that using a React component library to build the front-end user interface would both result in a better looking final
    product (we are not graphic designers and thus a React component library will certainly look better than what we could make) and offloading our effort
    to a component library will open up more time for us to implement more backend functionality which is what truly drives the value of this project.}
  \end{enumerate}


\end{enumerate}


\end{document}
